{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE1_TEST = \"/public/dsb_2018_data/stage1_test/\"\n",
    "STAGE1_TEST_IMAGE_PATTERN = \"%s/{}/images/{}.png\" % STAGE1_TEST\n",
    "SUBMISSION_IMAGEID = \"ImageId\"\n",
    "SUBMISSION_ENCODED = \"EncodedPixels\"\n",
    "models_path = [\n",
    "    \"/output/submission-np-ml-12-epochs-zero-mean-norm-resnet50-fix-test-norm.csv\",\n",
    "    \"/output/submission-np-ml-12-epochs-zero-mean-norm-resnet50-fix-test-norm.csv\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image loading\n",
    "def image_ids_in(root_dir):\n",
    "    ids = []\n",
    "    for id in os.listdir(root_dir):\n",
    "        ids.append(id)\n",
    "    return ids\n",
    "\n",
    "def read_image(image_id, pattern=STAGE1_TEST_IMAGE_PATTERN):\n",
    "    image_file = pattern.format(image_id, image_id)\n",
    "    image = skimage.io.imread(image_file)\n",
    "    # Drop alpha which is not used\n",
    "    image = image[:, :, :3]\n",
    "    return image\n",
    "\n",
    "def image_id_to_index(image_id, images_ids):\n",
    "    i = np.argwhere(np.array(images_ids) == image_id)[0][0]\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE decoding functions\n",
    "def rle_decode_one_mask(rle_str, mask_shape, mask_dtype):\n",
    "    s = rle_str.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    mask = np.zeros(np.prod(mask_shape), dtype=mask_dtype)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        mask[lo:hi] = 1\n",
    "    return mask.reshape(mask_shape[::-1]).T\n",
    "\n",
    "def rle_decode_all_masks(masks_str, mask_shape, mask_dtype):\n",
    "    image = None\n",
    "    i = 0\n",
    "    for mask_str in masks_str:\n",
    "        i = i + 1\n",
    "        mask = rle_decode_one_mask(mask_str, mask_shape, mask_dtype)\n",
    "        mask[mask == 1] = i\n",
    "        if image is None:\n",
    "            image = mask\n",
    "        else:\n",
    "            image = image + mask\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "test_image_ids = image_ids_in(STAGE1_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index image (unique value per mask) to array.\n",
    "def img_masks_as_masks_array(train_label):\n",
    "    # As (masks, height, width)\n",
    "    y_true = []\n",
    "    uniques = np.unique(train_label)\n",
    "    # Remove zero from index\n",
    "    indexes = np.delete(uniques, np.where(uniques == 0))\n",
    "    for index in indexes:\n",
    "        y_true.append(np.where(train_label == index, 1, 0))\n",
    "    y_true = np.array(y_true)\n",
    "    return y_true\n",
    "\n",
    "# Convert back all mask to index image\n",
    "def masks_array_to_index_image(masks):\n",
    "    mask = np.zeros((masks.shape[1], masks.shape[2]), dtype=np.uint16)\n",
    "    for index in range(0, masks.shape[0]):\n",
    "        mask[masks[index,:,:] > 0] = index + 1\n",
    "    return mask\n",
    "\n",
    "# Read image and predicted masks\n",
    "def read_test_image_mask(submissionPD, test_id):\n",
    "    test_image = read_image(test_id)\n",
    "    rle_encoded_masks = submissionPD[submissionPD[SUBMISSION_IMAGEID] == test_id][SUBMISSION_ENCODED].values\n",
    "    test_masks = rle_decode_all_masks(rle_encoded_masks, test_image.shape[:-1], np.int32)\n",
    "    test_masks_array = img_masks_as_masks_array(test_masks)\n",
    "    return test_image, test_masks_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract bounding box of mask\n",
    "def find_bounding_boxes_on_mask(bin_img, test_id, mask_id, with_ref=None):\n",
    "    boxes = []\n",
    "    img_bin = np.where(bin_img > 0, 1, 0)\n",
    "    img_rgb = (img_bin)*255\n",
    "    img_rgb = np.concatenate([img_rgb[:, :, np.newaxis], img_rgb[:, :, np.newaxis], img_rgb[:, :, np.newaxis]], axis=-1)\n",
    "    img_rgb = img_rgb.astype(np.uint8)\n",
    "    im_bw = cv2.cvtColor(img_rgb,cv2.COLOR_RGB2GRAY)\n",
    "    ret, im_bw = cv2.threshold(im_bw, 127, 255, cv2.THRESH_BINARY)\n",
    "    pixelpoints = cv2.findNonZero(im_bw)\n",
    "    x, y, w, h = cv2.boundingRect(pixelpoints)\n",
    "    if with_ref is not None:\n",
    "        boxes.append((x, y, w, h, with_ref, test_id, mask_id))\n",
    "    else:\n",
    "        boxes.append((x,y,w,h))\n",
    "    return np.array(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all bounding boxes\n",
    "def find_bounding_boxes_on_masks(test_masks_array, test_id, with_ref=None):\n",
    "    test_masks_pass = []\n",
    "    boxes_masks = []\n",
    "    for mask_id in range(0, len(test_masks_array)):\n",
    "        mask = test_masks_array[mask_id]\n",
    "        boxes = find_bounding_boxes_on_mask(mask, test_id, mask_id, with_ref=with_ref)\n",
    "        boxes_masks.append(boxes)\n",
    "        test_masks_pass.append(mask)\n",
    "    test_masks_pass = np.array(test_masks_pass)\n",
    "    boxes_masks = np.array(boxes_masks)\n",
    "    return test_masks_pass, boxes_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image and array of masks + bounding boxes for each model (for a given image).\n",
    "def models_cv_masks_for_image(models_path, test_id, test_image_ids):\n",
    "    test_id_ref = image_id_to_index(test_id, test_image_ids)\n",
    "    models_cv_masks = []\n",
    "    models_cv_masks_boxes = []\n",
    "    for i in range(0, len(models_path)):\n",
    "        model_path = models_path[i]\n",
    "        submission = pd.read_csv(model_path)\n",
    "        submission.dropna(subset=[SUBMISSION_ENCODED], inplace=True)\n",
    "        test_image, test_masks_array = read_test_image_mask(submission, test_id)\n",
    "        test_masks_clean, boxes_masks = find_bounding_boxes_on_masks(test_masks_array, test_id_ref, with_ref=i)\n",
    "        models_cv_masks.append(test_masks_clean)\n",
    "        models_cv_masks_boxes.append(boxes_masks)\n",
    "    return test_image, models_cv_masks, models_cv_masks_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic NMS on boxes, https://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python\n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,0] + boxes[:,2]\n",
    "    y2 = boxes[:,1] + boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of the bounding box and the smallest (x, y) coordinates for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the integer data type\n",
    "    return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute NMS (i.e. select only one box when multiple boxes overlap) for across models.\n",
    "def models_cv_masks_boxes_nms(models_cv_masks_boxes, threshold=0.3):\n",
    "    boxes = np.concatenate(models_cv_masks_boxes).squeeze()\n",
    "    boxes_nms = non_max_suppression_fast(boxes, threshold)\n",
    "    return boxes_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some result (on the nightmare images)\n",
    "# test_id = \"0f1f896d9ae5a04752d3239c690402c022db4d72c0d2c087d73380896f72c466\"\n",
    "test_id = \"472b1c5ff988dadc209faea92499bc07f305208dbda29d16262b3d543ac91c71\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '[185434,'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-972457a59315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get masks and boxes (one per mask) for each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks_cv_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks_boxes_cv_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_cv_masks_for_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-aef0b71dd30b>\u001b[0m in \u001b[0;36mmodels_cv_masks_for_image\u001b[0;34m(models_path, test_id, test_image_ids)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSUBMISSION_ENCODED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_test_image_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtest_masks_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_bounding_boxes_on_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_masks_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_id_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodels_cv_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_masks_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-cf75a1fa9daa>\u001b[0m in \u001b[0;36mread_test_image_mask\u001b[0;34m(submissionPD, test_id)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mrle_encoded_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmissionPD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmissionPD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSUBMISSION_IMAGEID\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSUBMISSION_ENCODED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtest_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrle_decode_all_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrle_encoded_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtest_masks_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_masks_as_masks_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-25302c640c61>\u001b[0m in \u001b[0;36mrle_decode_all_masks\u001b[0;34m(masks_str, mask_shape, mask_dtype)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmask_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmasks_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrle_decode_one_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-25302c640c61>\u001b[0m in \u001b[0;36mrle_decode_one_mask\u001b[0;34m(rle_str, mask_shape, mask_dtype)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrle_decode_one_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrle_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrle_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mstarts\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstarts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-25302c640c61>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrle_decode_one_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrle_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrle_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mstarts\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstarts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '[185434,'"
     ]
    }
   ],
   "source": [
    "# Get masks and boxes (one per mask) for each model\n",
    "test_image, test_masks_cv_array, test_masks_boxes_cv_array = models_cv_masks_for_image(models_path, test_id, test_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run NMS ensembling\n",
    "masks_boxes_nms = models_cv_masks_boxes_nms(test_masks_boxes_cv_array, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions of each model\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(masks_array_to_index_image(test_masks_cv_array[0]), cmap='nipy_spectral')\n",
    "ax[0].imshow(test_image, alpha=0.45)\n",
    "ax[0].set_title(\"Model#0: %d predicted instances for %s\"%(len(test_masks_cv_array[0]), models_path[0]))\n",
    "\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(masks_array_to_index_image(test_masks_cv_array[1]), cmap='nipy_spectral')\n",
    "ax[1].imshow(test_image, alpha=0.45)\n",
    "ax[1].set_title(\"Model#1: %d predicted instances for %s\"%(len(test_masks_cv_array[1]), models_path[1]))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxes for each model (left) and resulting NMS (right)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "ax[0].axis('off')\n",
    "ax[0].set_ylim(test_image.shape[0] + 10, -10)\n",
    "ax[0].set_xlim(-10, test_image.shape[1] + 10)\n",
    "cmap = plt.cm.get_cmap('nipy_spectral')\n",
    "# Plot boxes per model\n",
    "for box in np.concatenate(test_masks_boxes_cv_array).squeeze():\n",
    "    p = patches.Rectangle((box[0]-1, box[1]-1), box[2], box[3], linewidth=1, facecolor='none', edgecolor=cmap(box[4]*60), alpha=0.75, linestyle=\"dashed\")\n",
    "    ax[0].add_patch(p)\n",
    "    ax[0].text(box[0], box[1] + 8, \"%d\"%box[4], color=cmap(box[4]*60), size=10, backgroundcolor=\"none\") \n",
    "ax[0].imshow(test_image, alpha=0.6)\n",
    "ax[0].set_title(\"Bounding boxes of predicted instances for model #0 and #1\")\n",
    "\n",
    "# Plot NMS results\n",
    "ax[1].set_ylim(test_image.shape[0] + 10, -10)\n",
    "ax[1].set_xlim(-10, test_image.shape[1] + 10)\n",
    "ax[1].axis('off')\n",
    "for box_nms in masks_boxes_nms:\n",
    "    p = patches.Rectangle((box_nms[0]-1, box_nms[1]-1), box_nms[2], box_nms[3], linewidth=1, facecolor='yellow', alpha=0.25, linestyle=\"dashed\")\n",
    "    ax[1].add_patch(p)\n",
    "    ax[1].text(box_nms[0], box_nms[1] + 8, \"%d\"%box_nms[4], color=cmap(box_nms[4]*60), size=11, backgroundcolor=\"none\")  \n",
    "ax[1].imshow(test_image, alpha=0.6)\n",
    "ax[1].set_title(\"Ensemble NMS bounding boxes (%d) of predicted instances with its reference model #0 or #1\"%len(masks_boxes_nms))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to masks from NMS boxes\n",
    "def get_masks_from_boxes_nms(masks_boxes_nms, test_masks_cv_array):\n",
    "    masks_nms = []\n",
    "    for box_nms in masks_boxes_nms:\n",
    "        model_id = box_nms[4]\n",
    "        mask_id = box_nms[6]\n",
    "        mask_nms = test_masks_cv_array[model_id][mask_id]\n",
    "        masks_nms.append(mask_nms)\n",
    "    masks_nms = np.array(masks_nms)\n",
    "    return masks_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMS instances\n",
    "masks_nms = get_masks_from_boxes_nms(masks_boxes_nms, test_masks_cv_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot masks from NMS boxes\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "ax[0].axis('off')\n",
    "masks_nms_image = masks_array_to_index_image(masks_nms)\n",
    "ax[0].imshow(test_image)\n",
    "ax[0].set_title(\"%s\"%test_id)\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(masks_nms_image, cmap='nipy_spectral')\n",
    "ax[1].imshow(test_image, alpha=0.45)\n",
    "ax[1].set_title(\"Ensemble predicted instances (%d)\"%len(masks_nms))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE encoder\n",
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.T.flatten()\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    return rle\n",
    "\n",
    "def rle_encode_all_masks(masks):\n",
    "    values=list(np.unique(masks))\n",
    "    values.remove(0)\n",
    "    RLEs=[]\n",
    "    for v in values:\n",
    "        mask = np.where(masks == v, 1, 0)\n",
    "        rle = rle_encode_one_mask(mask)\n",
    "        rle_str = rle_to_string(rle)\n",
    "        RLEs.append(rle_str)\n",
    "    return RLEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission from NMS\n",
    "def generate_test_submission(image_ids, models_path):\n",
    "    results = []\n",
    "    for image_id in image_ids:\n",
    "        test_image, test_masks_cv_array, test_masks_boxes_cv_array = models_cv_masks_for_image(models_path, image_id, image_ids)\n",
    "        masks_boxes_nms = models_cv_masks_boxes_nms(test_masks_boxes_cv_array, threshold=0.3)\n",
    "        masks_nms = masks_array_to_index_image(get_masks_from_boxes_nms(masks_boxes_nms, test_masks_cv_array))\n",
    "        rle_encoded_masks = rle_encode_all_masks(masks_nms)\n",
    "        for rle_encoded_mask in rle_encoded_masks:\n",
    "            info = (image_id, rle_encoded_mask)\n",
    "            results.append(info)\n",
    "    df = pd.DataFrame(results, columns=[SUBMISSION_IMAGEID, SUBMISSION_ENCODED])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionPD = generate_test_submission(test_image_ids, models_path)\n",
    "submissionPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionPD.to_csv(\"submission.csv\", index=False, sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
